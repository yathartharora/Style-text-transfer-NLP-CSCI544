{"cells":[{"cell_type":"markdown","metadata":{"id":"54-QyBZlJ7vS"},"source":["# Head Selection\n","**_BERT_** is a **_Multi-layer_ _Multi-Head_** Transformer architecture. As discuss in many of the current reseachers, different Attention heads captures different lingustic patterns. For a better deletion of words using Attention mechanism we need to choose a head which **captures pattern useful for classification.**\n","\n","To do this we are using a Brute force mechanism to seach through all the possible heads. We are deleting TopK words attended by different heads from the sentence and measuring the new classification score. In case of sentiments, removing sentiments related words makes the sentence neutral. The heads are sorted by the amount to which it is able to make the sentences from dev set to Neutral."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"raImr_xGJ_pQ","executionInfo":{"status":"ok","timestamp":1682392437130,"user_tz":420,"elapsed":26097,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"12346de9-d9ee-47ed-c7ad-a8f20925fcc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["! pip install boto3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fEYM14XKTv-","executionInfo":{"status":"ok","timestamp":1682392448050,"user_tz":420,"elapsed":10931,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"425c8162-f9e1-4c59-c686-1c288f41c152"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting boto3\n","  Downloading boto3-1.26.119-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.30.0,>=1.29.119\n","  Downloading botocore-1.29.119-py3-none-any.whl (10.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.119->boto3) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.119->boto3) (1.26.15)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.119->boto3) (1.16.0)\n","Installing collected packages: jmespath, botocore, s3transfer, boto3\n","Successfully installed boto3-1.26.119 botocore-1.29.119 jmespath-1.0.1 s3transfer-0.6.0\n"]}]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/transformer-drg-style-transfer-master\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bdNQgrcoKcOv","executionInfo":{"status":"ok","timestamp":1682392450224,"user_tz":420,"elapsed":5,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"4b5b8df2-4091-4f3a-944e-fd696c006864"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1TCvtUjcTYKWgalUeZbJk_aFhLp1aLjr6/transformer-drg-style-transfer-master\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqUmYeL5J7vY","executionInfo":{"status":"ok","timestamp":1682392484572,"user_tz":420,"elapsed":32688,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"89178742-3ee1-48a5-a3a2-a0e4d1a7ab93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"]}],"source":["import csv\n","import logging\n","import os\n","import random\n","import sys\n","import numpy as np\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm, trange\n","\n","from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n","from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n","#from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n","\n","from bertviz.bertviz import attention, visualization\n","from bertviz.bertviz.pytorch_pretrained_bert import BertModel, BertTokenizer\n","\n","logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                    datefmt = '%m/%d/%Y %H:%M:%S',\n","                    level = logging.INFO)"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71F_jYs3-VGn","executionInfo":{"status":"ok","timestamp":1682392496352,"user_tz":420,"elapsed":11801,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"4df88e8b-aa3b-4ef1-af45-96bd641d6699"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.0 tokenizers-0.13.3 transformers-4.28.1\n"]}]},{"cell_type":"code","source":["from transformers import (\n","    BertForSequenceClassification,\n","    BertTokenizer,\n","    RobertaModel,\n","    RobertaForSequenceClassification,\n","    RobertaTokenizer,\n","    AdamW)"],"metadata":{"id":"Vf9V5ehO-Txp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9hVJyrRJ7vZ"},"outputs":[],"source":["logger = logging.getLogger(__name__)\n","bert_classifier_model_dir = \"/content/drive/MyDrive/transformer-drg-style-transfer-master/robertaOutput/roberta.pt\" ## Path of BERT classifier model path\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","logger.info(\"device: {}, n_gpu {}\".format(device, n_gpu))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":931,"referenced_widgets":["d4ffb815451745a4afe77b115e9a89e6","8daac63208fe427a92a63b4ea90d9348","daf4a396e75645cf87449b7767369c77","af03c712b15945cab469a6c1d16c3ea8","d35cd93c1e3047dd911e38667362c37f","ff714ed6fa324e8b88f1835b72b56404","674c6edf77784d01b855c9d3f3eebc9b","322f8924751e4149bd896aab10ebb11c","e2f9d2c6fe1c47e3b4401eef77d315bb","cb9bd84a84c44d849d9adc086493fc42","99977cf33bcf4d77b4d6bedfe534f945","faf068f8e9d9439b8917d570ffa40226","fb8fa35e4869496bb84fdcebaffd4c2a","96cf93df39374e34b428f4826c29b516","69bd19a646344afd939ca1cab7903886","1a976cbc8c804f4f91e2d672eb1511eb","2f75e51d19e543bd82c1d12eb75a1fba","45c59260388548be867ba7751fdfecd6","68bcb67aa8314a5e89c9c61291cf206f","892c2f02631d4c369dc795562fa220d8","400306f57f894fcc95c093ca953ce6dc","3f4a6a41d5de4f678cef4c33200e2617","2d1160b1be2043cfb878a5184740d74e","a5100a7cd55346ff95f992fbcf86665e","8c74534c42494343a0a0c1168871bb0e","e16fc088b4184a9ca7b4080e780f877e","4ff75f6181424c779c984130954cfaca","62f2398f496a4f8b881151127793f743","f5006bea2c06493fb8e1f8352220e7e6","0ceae35a35d54105a22e6bc7f9d19178","7b7cb9fd5d1d46b790d03e8277a2b0cb","520e7aacf8224a5ca1afdb4c4d512390","3dbad419a2474b0c9a6ed4c671d855b3","1f3466224e564dada54407913b96bf3f","56b0d5c22c80464c8510cb985d46e44b","58b46cb813e342f6a0b37efc9f0ba36b","cb721d3457684702bab7e37973b10c94","709d118a2a7f42329a66459ccff59f21","8aa13904ca3740f5a87f21eefeca2693","aa3288783cdf457d8de5de896be8d773","37296bd3f2de4398964554493dabb2c7","833d2abe36814719822407fbd1d5fffe","2c22272bfd6a4335a418e90e7e8a0cc2","fb7224cfd36d483ba0ce33e98cfde479"]},"id":"TTXGgn3xJ7vZ","executionInfo":{"status":"ok","timestamp":1682392607783,"user_tz":420,"elapsed":88612,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"69d64645-7c8a-438c-9428-f238d15f9749"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4ffb815451745a4afe77b115e9a89e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf068f8e9d9439b8917d570ffa40226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d1160b1be2043cfb878a5184740d74e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f3466224e564dada54407913b96bf3f"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":8}],"source":["## Model for performing Classification\n","roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","model_dict = torch.load('/content/drive/MyDrive/transformer-drg-style-transfer-master/robertaOutput/roberta.pt', map_location=device)\n","model_cls = RobertaForSequenceClassification.from_pretrained(pretrained_model_name_or_path='roberta-base', state_dict=model_dict)\n","model_cls.to(device)\n","model_cls.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mETLbZsNJ7vZ","executionInfo":{"status":"ok","timestamp":1682392622959,"user_tz":420,"elapsed":15191,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"fd854785-6da6-4c59-c113-2ad375e93f17"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaModel(\n","  (embeddings): RobertaEmbeddings(\n","    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","    (position_embeddings): Embedding(514, 768, padding_idx=1)\n","    (token_type_embeddings): Embedding(1, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): RobertaEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (crossattention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): RobertaPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":9}],"source":["## Model to get the attention weights of all the heads\n","model_dict = torch.load('/content/drive/MyDrive/transformer-drg-style-transfer-master/robertaOutput/roberta.pt', map_location=device)\n","model = RobertaModel.from_pretrained(pretrained_model_name_or_path='roberta-base', state_dict=model_dict, add_cross_attention=True, is_decoder = True)\n","\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","model.to(device)\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FLyHKBnAJ7vZ"},"outputs":[],"source":["max_seq_len=70 # Maximum sequence length \n","sm = torch.nn.Softmax(dim=-1) ## Softmax over the batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87nNQv8HJ7vZ"},"outputs":[],"source":["def run_multiple_examples(input_sentences, bs=32):\n","    \"\"\"\n","    This fucntion returns classification predictions for batch of sentences.\n","    input_sentences: list of strings\n","    bs : batch_size : int\n","    \"\"\"\n","\n","\n","    ids = []\n","    segment_ids = []\n","    input_masks = []\n","    pred_lt = []\n","    ids_for_decoding = []\n","\n","    roberta_input_ids = []\n","    roberta_attention_masks = []\n","    sentence_ids = []\n","    counter = 0\n","    pred_lt = []\n","\n","    for sen in input_sentences:\n","      roberta_encoded_dict = roberta_tokenizer.encode_plus(\n","                        sen,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","      roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n","      roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n","      ids_for_decoding.append(roberta_encoded_dict['input_ids'])\n","      sentence_ids.append(counter)\n","      counter  = counter + 1\n","    roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n","    roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n","    roberta_dataset = TensorDataset(roberta_input_ids, roberta_attention_masks)\n","    roberta_train_dataloader = DataLoader(\n","            roberta_dataset,  # The training samples.\n","            sampler = RandomSampler(roberta_dataset), # Select batches randomly\n","            batch_size = 32 # Trains with this batch size.\n","        )\n","    for step, batch in enumerate(roberta_train_dataloader):\n","      b_input_ids = batch[0].to(device)\n","      b_input_mask = batch[1].to(device)\n","      with torch.no_grad():\n","        logits = model_cls(b_input_ids, b_input_mask).logits\n","        preds = sm(logits)\n","        print(logits.size(), preds.size())\n","      pred_lt.extend(preds.tolist())\n","    return pred_lt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHLEH842J7va"},"outputs":[],"source":["def read_file(path,size):\n","    with open(path) as fp:\n","        data = fp.read().splitlines()[:size]\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBCytaOnJ7va"},"outputs":[],"source":["def get_attention_for_batch(input_sentences , bs=32):\n","    \"\"\"\n","    This function calculates attention weights of all the heads and\n","    returns it along with the encoded sentence for further processing.\n","    \n","    input sentence: list of strings\n","    bs : batch_size\n","    \"\"\"\n","    \n","    ## Preprocessing for BERT \n","    ids = []\n","    segment_ids = []\n","    input_masks = []\n","    pred_lt = []\n","    ids_for_decoding = []\n","\n","    roberta_input_ids = []\n","    roberta_attention_masks = []\n","    sentence_ids = []\n","    counter = 0\n","    all_attn_probs = []\n","\n","    for sen in input_sentences:\n","      roberta_encoded_dict = roberta_tokenizer.encode_plus(\n","                        sen,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","      roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n","      roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n","      ids_for_decoding.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"<s>\" + sen + \"</s>\")))\n","      sentence_ids.append(counter)\n","      counter  = counter + 1\n","    roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n","    roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n","    roberta_dataset = TensorDataset(roberta_input_ids, roberta_attention_masks)\n","    roberta_train_dataloader = DataLoader(\n","            roberta_dataset,  # The training samples.\n","            sampler = RandomSampler(roberta_dataset), # Select batches randomly\n","            batch_size = 32 # Trains with this batch size.\n","        )\n","    for step, batch in enumerate(roberta_train_dataloader):\n","      batch_attn_probs = []\n","      b_input_ids = batch[0].to(device)\n","      b_input_mask = batch[1].to(device)\n","      with torch.no_grad():\n","        attn = model(b_input_ids, b_input_mask, output_attentions=True).cross_attentions\n","      attn = list(attn)\n","      # for k in range(len(attn)):\n","      #   # attn[k] = list(attn[k])\n","      #   attn[k] = attn[k].to('cpu')\n","      # # print(len(attn_b[0]), len(attn_b[0][0]), len(attn_b[0][0][0]), len(attn_b[0][0][0][0]))\n","      # if step == 0:\n","      #   att_lt = attn\n","      #   heads = len(att_lt)\n","      #   # print((att_lt[0]))\n","      # else:\n","      #   for j in range(12):\n","      #       att_lt[j] = torch.cat((att_lt[j], attn[j]),0)\n","      \n","      for layer in attn:\n","        # print(layer[0].size()) #([32, 12, 128, 64]\n","        batch_attn_probs.append(layer[0].detach().cpu().unsqueeze(1))\n","      batch_attn_probs = torch.cat(batch_attn_probs, dim=1)  # Shape: (batch_size, num_heads, sequence_length, sequence_length)\n","      all_attn_probs.append(batch_attn_probs)\n","\n","    # Stack the attention weights across all batches\n","    all_attn_probs = torch.cat(all_attn_probs, dim=0)  # Shape: (total_data, num_heads, sequence_length, sequence_length)\n","\n","    # Transpose to get the required shape\n","    # Shape: (num_layers, sequence_length, total_data, num_heads, sequence_length)\n","\n","    all_attn_probs = all_attn_probs.transpose(0, 1)  # Shape: (num_layers, num_heads, total_data, sequence_length, sequence_length)\n","    # return att_lt, ids_for_decoding\n","    return all_attn_probs, ids_for_decoding\n","    \n","    # return att_lt, ids_for_decoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sB-dyJs3J7va"},"outputs":[],"source":["def process_sentences(input_sentences, att, decoding_ids, threshold=0.25):\n","    \"\"\"\n","    This function processes each input sentence by removing the top tokens defined threshold value.\n","    Each sentence is processed for each head.\n","    \n","    input_ids: list of strings\n","    decoding_ids: indexed input_sentnces thus len(input_sentences) == len(decoding_ids)\n","    threshold: Percentage of the top indexes to be removed\n","    \"\"\"\n","    # List of None of num_of_layers * num_of_heads to save the results of each head for input_sentences\n","    \n","    lt = [None for x in range(len(att) * len(att[0][0]))]\n","    \n","    \n","    inx = 0\n","    for i in trange(len(att)): #  For all the layers\n","        for j in range(len(att[i][0])): # For all the heads in the ith Layer\n","            processed_sen = [None for q in decoding_ids] # List of len(decoding_ids)\n","            for k in range(len(input_sentences)): # For all the senteces \n","                _, topi = att[i][k][j][0].topk(len(decoding_ids[k])) # Get top attended ids\n","                topi = topi.tolist()\n","                topi = topi[:int(len(topi) * threshold)] \n","                print(topi)\n","                ## Decode the sentece after removing the topk indexes\n","                final_indexes = []\n","                count = 0\n","                count1 = 0\n","                # tokens = [\"[CLS]\"] + tokenizer.tokenize(input_sentences[k]) + [\"[SEP]\"]\n","                roberta_encoded_dict = roberta_tokenizer.encode_plus(\n","                        input_sentences[k],                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 128,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","                tokens = roberta_encoded_dict['input_ids']\n","                # print(decoding_ids[k], tokens[0][0])\n","                while count < len(decoding_ids[k]):\n","                    if count in topi: # Remove index if present in topk\n","                        while (count + count1 + 1) < len(decoding_ids[k]):\n","                            if \"##\" in str(tokens[0][count + count1 + 1]):\n","                                count1 += 1\n","                            else:\n","                                break\n","                        count += count1\n","                        count1 = 0\n","                        # continue\n","                        # pass\n","                    else: # Else add to the decoded sentence\n","                        final_indexes.append(decoding_ids[k][count])\n","                    count += 1\n","                tmp = tokenizer.convert_ids_to_tokens(final_indexes[0]) # Convert ids to token\n","                # Convert toknes to sentence\n","                processed_sen[k] = \" \".join(tmp).replace('Ġ', '').replace(\" ##\", \"\").replace(\"<s>\",\"\").replace(\"</s>\",\"\").replace(\"<pad>\",\"\").strip()\n","            lt[inx] = processed_sen # Store sentences for inxth head\n","            inx += 1\n","    \n","    return lt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaKFGJriJ7va"},"outputs":[],"source":["def get_block_head(processed_sentence_list, lmbd = 0.1):\n","    \"\"\"\n","    This function calculate classification scores for sentences generated by each head\n","    and sort them from best to worst.\n","    score = min(pred) + lmbd / max(pred) + lmbd, lmbd is smoothing param\n","    pred is list of probability score for each class, for best case pred = [0.5, 0.5] ==> score = 1\n","    \n","    it returns sorted list of (Layer, Head, Score)\n","    \"\"\"\n","    scores = {}\n","    #scores_1 = {}\n","    for i in trange(len(processed_sentence_list)): # sentences by each head\n","        pred = np.array(run_multiple_examples(processed_sentence_list[i]))\n","        scores[i] = np.mean([(min(x[0], x[1])+lmbd)/(max(x[0], x[1])+lmbd) for x in pred])\n","        #scores_1[i] = np.mean([abs(max(x[0],x[1]) - min(x[0],x[1])) for x in pred])\n","    temp = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n","    #temp1 = sorted(scores_1.items(), key=lambda kv: kv[1], reverse=False)\n","    score_lt = [(x // 12, x - (12 * (x // 12)),y) for x,y in temp]\n","    #score1_lt = [(x // 12, x - (12 * (x // 12)),y) for x,y in temp1]\n","    return score_lt  #score1_lt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKlSqsiGJ7va"},"outputs":[],"source":["pos_examples_file = \"/content/drive/MyDrive/transformer-drg-style-transfer-master/data/yelp/sentiment.dev.1\"\n","neg_examples_file = \"/content/drive/MyDrive/transformer-drg-style-transfer-master/data/yelp/sentiment.dev.0\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBPBO4LuJ7vb"},"outputs":[],"source":["'''\n","100 examples from each class worked good, the bottlenack is the run_multiple_examples() function,\n","with higher memory (either with cpu of gpu) one can reduce the processing time by incresing batch_size.\n","With batch_size of 32 it takes around 24 mins for 100 example on cpu.\n","'''\n","pos_data = read_file(pos_examples_file,100)\n","neg_data = read_file(neg_examples_file,100)\n","data = pos_data + neg_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9i8M3KPlJ7vb","executionInfo":{"status":"ok","timestamp":1682392763341,"user_tz":420,"elapsed":9,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"eafe379c-b254-4d3f-def0-98ff05edb44d"},"outputs":[{"output_type":"stream","name":"stdout","text":["100 100 200\n"]}],"source":["print(len(pos_data), len(neg_data), len(data))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QggovyacJ7vb","executionInfo":{"status":"ok","timestamp":1682392772657,"user_tz":420,"elapsed":6582,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"adf8f94a-d61f-400e-fc27-cde9df793774"},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["att, decoding_ids = get_attention_for_batch(data)"]},{"cell_type":"code","source":["print(len(att), len(att[0]), len(att[0][0]),len(att[0][0][0]), len(att[0][0][0][0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VgnQSKvHtaf","executionInfo":{"status":"ok","timestamp":1682392772657,"user_tz":420,"elapsed":7,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"ec68ccf7-0cff-4c8b-f5c8-27d0b88f24bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12 200 12 128 64\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_drOG-oJ7vb"},"outputs":[],"source":["sen_list = process_sentences(data, att, decoding_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFh5qAk8J7vb"},"outputs":[],"source":["scores = get_block_head(sen_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yWfgbjIJ7vb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682392993258,"user_tz":420,"elapsed":503,"user":{"displayName":"RIYA TASGAONKAR","userId":"14738685921834546470"}},"outputId":"75e36974-5b5c-438f-e569-77ab449451fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(8, 3, 0.23401291897378357),\n"," (7, 9, 0.23401291830588036),\n"," (10, 3, 0.23401291595791934),\n"," (1, 7, 0.21455849389106824),\n"," (3, 6, 0.21455849346674674),\n"," (7, 1, 0.21455849223055182),\n"," (11, 8, 0.2145584855443996),\n"," (6, 10, 0.20277125066330964),\n"," (8, 5, 0.20277125066330964),\n"," (0, 0, 0.18875358972700407),\n"," (0, 1, 0.18875358972700407),\n"," (0, 2, 0.18875358972700407),\n"," (0, 3, 0.18875358972700407),\n"," (0, 4, 0.18875358972700407),\n"," (0, 5, 0.18875358972700407),\n"," (0, 6, 0.18875358972700407),\n"," (0, 7, 0.18875358972700407),\n"," (0, 8, 0.18875358972700407),\n"," (0, 9, 0.18875358972700407),\n"," (0, 10, 0.18875358972700407),\n"," (0, 11, 0.18875358972700407),\n"," (1, 0, 0.18875358972700407),\n"," (1, 1, 0.18875358972700407),\n"," (1, 2, 0.18875358972700407),\n"," (1, 3, 0.18875358972700407),\n"," (1, 4, 0.18875358972700407),\n"," (1, 5, 0.18875358972700407),\n"," (1, 6, 0.18875358972700407),\n"," (1, 8, 0.18875358972700407),\n"," (1, 9, 0.18875358972700407),\n"," (1, 10, 0.18875358972700407),\n"," (1, 11, 0.18875358972700407),\n"," (2, 0, 0.18875358972700407),\n"," (2, 1, 0.18875358972700407),\n"," (2, 2, 0.18875358972700407),\n"," (2, 3, 0.18875358972700407),\n"," (2, 4, 0.18875358972700407),\n"," (2, 5, 0.18875358972700407),\n"," (2, 6, 0.18875358972700407),\n"," (2, 7, 0.18875358972700407),\n"," (2, 8, 0.18875358972700407),\n"," (2, 9, 0.18875358972700407),\n"," (2, 10, 0.18875358972700407),\n"," (2, 11, 0.18875358972700407),\n"," (3, 0, 0.18875358972700407),\n"," (3, 1, 0.18875358972700407),\n"," (3, 2, 0.18875358972700407),\n"," (3, 3, 0.18875358972700407),\n"," (3, 4, 0.18875358972700407),\n"," (3, 5, 0.18875358972700407),\n"," (3, 7, 0.18875358972700407),\n"," (3, 8, 0.18875358972700407),\n"," (3, 9, 0.18875358972700407),\n"," (3, 10, 0.18875358972700407),\n"," (3, 11, 0.18875358972700407),\n"," (4, 0, 0.18875358972700407),\n"," (4, 1, 0.18875358972700407),\n"," (4, 2, 0.18875358972700407),\n"," (4, 3, 0.18875358972700407),\n"," (4, 4, 0.18875358972700407),\n"," (4, 5, 0.18875358972700407),\n"," (4, 6, 0.18875358972700407),\n"," (4, 7, 0.18875358972700407),\n"," (4, 8, 0.18875358972700407),\n"," (4, 9, 0.18875358972700407),\n"," (4, 10, 0.18875358972700407),\n"," (4, 11, 0.18875358972700407),\n"," (5, 0, 0.18875358972700407),\n"," (5, 1, 0.18875358972700407),\n"," (5, 2, 0.18875358972700407),\n"," (5, 3, 0.18875358972700407),\n"," (5, 4, 0.18875358972700407),\n"," (5, 5, 0.18875358972700407),\n"," (5, 6, 0.18875358972700407),\n"," (5, 7, 0.18875358972700407),\n"," (5, 8, 0.18875358972700407),\n"," (5, 9, 0.18875358972700407),\n"," (5, 10, 0.18875358972700407),\n"," (5, 11, 0.18875358972700407),\n"," (6, 0, 0.18875358972700407),\n"," (6, 1, 0.18875358972700407),\n"," (6, 2, 0.18875358972700407),\n"," (6, 3, 0.18875358972700407),\n"," (6, 4, 0.18875358972700407),\n"," (6, 5, 0.18875358972700407),\n"," (6, 6, 0.18875358972700407),\n"," (6, 7, 0.18875358972700407),\n"," (6, 8, 0.18875358972700407),\n"," (6, 9, 0.18875358972700407),\n"," (6, 11, 0.18875358972700407),\n"," (7, 0, 0.18875358972700407),\n"," (7, 2, 0.18875358972700407),\n"," (7, 3, 0.18875358972700407),\n"," (7, 4, 0.18875358972700407),\n"," (7, 5, 0.18875358972700407),\n"," (7, 6, 0.18875358972700407),\n"," (7, 7, 0.18875358972700407),\n"," (7, 8, 0.18875358972700407),\n"," (7, 10, 0.18875358972700407),\n"," (7, 11, 0.18875358972700407),\n"," (8, 0, 0.18875358972700407),\n"," (8, 1, 0.18875358972700407),\n"," (8, 2, 0.18875358972700407),\n"," (8, 4, 0.18875358972700407),\n"," (8, 6, 0.18875358972700407),\n"," (8, 7, 0.18875358972700407),\n"," (8, 8, 0.18875358972700407),\n"," (8, 9, 0.18875358972700407),\n"," (8, 10, 0.18875358972700407),\n"," (8, 11, 0.18875358972700407),\n"," (9, 0, 0.18875358972700407),\n"," (9, 1, 0.18875358972700407),\n"," (9, 2, 0.18875358972700407),\n"," (9, 3, 0.18875358972700407),\n"," (9, 4, 0.18875358972700407),\n"," (9, 5, 0.18875358972700407),\n"," (9, 6, 0.18875358972700407),\n"," (9, 7, 0.18875358972700407),\n"," (9, 8, 0.18875358972700407),\n"," (9, 9, 0.18875358972700407),\n"," (9, 10, 0.18875358972700407),\n"," (9, 11, 0.18875358972700407),\n"," (10, 0, 0.18875358972700407),\n"," (10, 1, 0.18875358972700407),\n"," (10, 2, 0.18875358972700407),\n"," (10, 4, 0.18875358972700407),\n"," (10, 5, 0.18875358972700407),\n"," (10, 6, 0.18875358972700407),\n"," (10, 7, 0.18875358972700407),\n"," (10, 8, 0.18875358972700407),\n"," (10, 9, 0.18875358972700407),\n"," (10, 10, 0.18875358972700407),\n"," (10, 11, 0.18875358972700407),\n"," (11, 0, 0.18875358972700407),\n"," (11, 1, 0.18875358972700407),\n"," (11, 2, 0.18875358972700407),\n"," (11, 3, 0.18875358972700407),\n"," (11, 4, 0.18875358972700407),\n"," (11, 5, 0.18875358972700407),\n"," (11, 6, 0.18875358972700407),\n"," (11, 7, 0.18875358972700407),\n"," (11, 9, 0.18875358972700407),\n"," (11, 10, 0.18875358972700407),\n"," (11, 11, 0.18875358972700407)]"]},"metadata":{},"execution_count":23}],"source":["scores"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"provenance":[],"gpuType":"T4"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d4ffb815451745a4afe77b115e9a89e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8daac63208fe427a92a63b4ea90d9348","IPY_MODEL_daf4a396e75645cf87449b7767369c77","IPY_MODEL_af03c712b15945cab469a6c1d16c3ea8"],"layout":"IPY_MODEL_d35cd93c1e3047dd911e38667362c37f"}},"8daac63208fe427a92a63b4ea90d9348":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff714ed6fa324e8b88f1835b72b56404","placeholder":"​","style":"IPY_MODEL_674c6edf77784d01b855c9d3f3eebc9b","value":"Downloading (…)olve/main/vocab.json: 100%"}},"daf4a396e75645cf87449b7767369c77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_322f8924751e4149bd896aab10ebb11c","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2f9d2c6fe1c47e3b4401eef77d315bb","value":898823}},"af03c712b15945cab469a6c1d16c3ea8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb9bd84a84c44d849d9adc086493fc42","placeholder":"​","style":"IPY_MODEL_99977cf33bcf4d77b4d6bedfe534f945","value":" 899k/899k [00:00&lt;00:00, 1.12MB/s]"}},"d35cd93c1e3047dd911e38667362c37f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff714ed6fa324e8b88f1835b72b56404":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"674c6edf77784d01b855c9d3f3eebc9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"322f8924751e4149bd896aab10ebb11c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2f9d2c6fe1c47e3b4401eef77d315bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb9bd84a84c44d849d9adc086493fc42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99977cf33bcf4d77b4d6bedfe534f945":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faf068f8e9d9439b8917d570ffa40226":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb8fa35e4869496bb84fdcebaffd4c2a","IPY_MODEL_96cf93df39374e34b428f4826c29b516","IPY_MODEL_69bd19a646344afd939ca1cab7903886"],"layout":"IPY_MODEL_1a976cbc8c804f4f91e2d672eb1511eb"}},"fb8fa35e4869496bb84fdcebaffd4c2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f75e51d19e543bd82c1d12eb75a1fba","placeholder":"​","style":"IPY_MODEL_45c59260388548be867ba7751fdfecd6","value":"Downloading (…)olve/main/merges.txt: 100%"}},"96cf93df39374e34b428f4826c29b516":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68bcb67aa8314a5e89c9c61291cf206f","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_892c2f02631d4c369dc795562fa220d8","value":456318}},"69bd19a646344afd939ca1cab7903886":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_400306f57f894fcc95c093ca953ce6dc","placeholder":"​","style":"IPY_MODEL_3f4a6a41d5de4f678cef4c33200e2617","value":" 456k/456k [00:00&lt;00:00, 728kB/s]"}},"1a976cbc8c804f4f91e2d672eb1511eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f75e51d19e543bd82c1d12eb75a1fba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45c59260388548be867ba7751fdfecd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68bcb67aa8314a5e89c9c61291cf206f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"892c2f02631d4c369dc795562fa220d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"400306f57f894fcc95c093ca953ce6dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f4a6a41d5de4f678cef4c33200e2617":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d1160b1be2043cfb878a5184740d74e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5100a7cd55346ff95f992fbcf86665e","IPY_MODEL_8c74534c42494343a0a0c1168871bb0e","IPY_MODEL_e16fc088b4184a9ca7b4080e780f877e"],"layout":"IPY_MODEL_4ff75f6181424c779c984130954cfaca"}},"a5100a7cd55346ff95f992fbcf86665e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62f2398f496a4f8b881151127793f743","placeholder":"​","style":"IPY_MODEL_f5006bea2c06493fb8e1f8352220e7e6","value":"Downloading (…)lve/main/config.json: 100%"}},"8c74534c42494343a0a0c1168871bb0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ceae35a35d54105a22e6bc7f9d19178","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b7cb9fd5d1d46b790d03e8277a2b0cb","value":481}},"e16fc088b4184a9ca7b4080e780f877e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_520e7aacf8224a5ca1afdb4c4d512390","placeholder":"​","style":"IPY_MODEL_3dbad419a2474b0c9a6ed4c671d855b3","value":" 481/481 [00:00&lt;00:00, 33.0kB/s]"}},"4ff75f6181424c779c984130954cfaca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62f2398f496a4f8b881151127793f743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5006bea2c06493fb8e1f8352220e7e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ceae35a35d54105a22e6bc7f9d19178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b7cb9fd5d1d46b790d03e8277a2b0cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"520e7aacf8224a5ca1afdb4c4d512390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dbad419a2474b0c9a6ed4c671d855b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f3466224e564dada54407913b96bf3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56b0d5c22c80464c8510cb985d46e44b","IPY_MODEL_58b46cb813e342f6a0b37efc9f0ba36b","IPY_MODEL_cb721d3457684702bab7e37973b10c94"],"layout":"IPY_MODEL_709d118a2a7f42329a66459ccff59f21"}},"56b0d5c22c80464c8510cb985d46e44b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aa13904ca3740f5a87f21eefeca2693","placeholder":"​","style":"IPY_MODEL_aa3288783cdf457d8de5de896be8d773","value":"Downloading pytorch_model.bin: 100%"}},"58b46cb813e342f6a0b37efc9f0ba36b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37296bd3f2de4398964554493dabb2c7","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_833d2abe36814719822407fbd1d5fffe","value":501200538}},"cb721d3457684702bab7e37973b10c94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c22272bfd6a4335a418e90e7e8a0cc2","placeholder":"​","style":"IPY_MODEL_fb7224cfd36d483ba0ce33e98cfde479","value":" 501M/501M [00:01&lt;00:00, 271MB/s]"}},"709d118a2a7f42329a66459ccff59f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa13904ca3740f5a87f21eefeca2693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa3288783cdf457d8de5de896be8d773":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37296bd3f2de4398964554493dabb2c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"833d2abe36814719822407fbd1d5fffe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c22272bfd6a4335a418e90e7e8a0cc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb7224cfd36d483ba0ce33e98cfde479":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}