{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZZ-2fvq0ndn","executionInfo":{"status":"ok","timestamp":1681678120064,"user_tz":420,"elapsed":15463,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}},"outputId":"7e93c424-5965-4d23-8d73-55e7858f2c50"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"aH22uVaY0m6C","executionInfo":{"status":"ok","timestamp":1681679464191,"user_tz":420,"elapsed":2,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}}},"outputs":[],"source":["import os, csv\n","from tqdm import tqdm, trange"]},{"cell_type":"code","source":["! pip install boto3"],"metadata":{"id":"r47vfsQo3pMH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681679470556,"user_tz":420,"elapsed":5155,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}},"outputId":"c844ee15-ee3e-409d-b67e-b66d38af49bb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.9/dist-packages (1.26.114)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3) (1.0.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3) (0.6.0)\n","Requirement already satisfied: botocore<1.30.0,>=1.29.114 in /usr/local/lib/python3.9/dist-packages (from boto3) (1.29.114)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.114->boto3) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.114->boto3) (1.26.15)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.114->boto3) (1.16.0)\n"]}]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/transformer-drg-style-transfer-master/data\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knf7yBic450z","executionInfo":{"status":"ok","timestamp":1681679470556,"user_tz":420,"elapsed":4,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}},"outputId":"1df87757-c4f4-4bed-d668-c3e2194ea7a3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/transformer-drg-style-transfer-master/data\n"]}]},{"cell_type":"code","execution_count":52,"metadata":{"id":"fpTEa4Ar0m6G","executionInfo":{"status":"ok","timestamp":1681681017089,"user_tz":420,"elapsed":147,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}}},"outputs":[],"source":["# file paths\n","data_dir = \"/content/drive/MyDrive/transformer-drg-style-transfer-master/data\"\n","dataset = \"imagecaption\" # amazon / yelp / imagecaption\n","train_0 = os.path.join(data_dir ,\"{}/sentiment.train.0\".format(dataset))\n","train_1 = os.path.join(data_dir,\"{}/sentiment.train.1\".format(dataset))\n","test_0 = os.path.join(data_dir,\"{}/sentiment.test.0\".format(dataset))\n","test_1 = os.path.join(data_dir,\"{}/sentiment.test.1\".format(dataset))\n","dev_0 = os.path.join(data_dir,\"{}/sentiment.dev.0\".format(dataset))\n","dev_1 = os.path.join(data_dir,\"{}/sentiment.dev.1\".format(dataset))\n","reference_0 = os.path.join(data_dir,\"{}/reference.0\".format(dataset))\n","reference_1 = os.path.join(data_dir,\"{}/reference.1\".format(dataset))"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"Yl2HaZpx0m6H","executionInfo":{"status":"ok","timestamp":1681681017993,"user_tz":420,"elapsed":136,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}}},"outputs":[],"source":["train_out = os.path.join(data_dir,\"{}/bert_classifier_training/train.csv\".format(dataset))\n","dev_out = os.path.join(data_dir,\"{}/bert_classifier_training/dev.csv\".format(dataset))\n","test_out = os.path.join(data_dir,\"{}/bert_classifier_training/test.csv\".format(dataset))"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"z8dnE0ij0m6H","executionInfo":{"status":"ok","timestamp":1681681019104,"user_tz":420,"elapsed":192,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}}},"outputs":[],"source":["def create_classification_file(input_file_path_list, input_file_label_list, output_file_path):\n","    \"\"\"\n","    Create a csv file combining training data for BERT classification training.\n","    input_file_path_list : Path of the input files\n","    input_file_label_list : Correspoding labels for input_files\n","    output_file_path : csv file path\n","    \"\"\"\n","    with open(output_file_path, \"w\") as out_fp:\n","        writer = csv.writer(out_fp, delimiter=\"\\t\")\n","        for i, file in enumerate(tqdm(input_file_path_list)):\n","            with open(file) as fp:\n","                for line in fp:\n","                  writer.writerow([line.strip(),input_file_label_list[i]])"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GgCLhwPa0m6I","executionInfo":{"status":"ok","timestamp":1681681020622,"user_tz":420,"elapsed":254,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}},"outputId":"8160c77a-e127-4771-c834-bea8907c67f3"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2/2 [00:00<00:00, 59.37it/s]\n","100%|██████████| 2/2 [00:00<00:00, 378.07it/s]\n","100%|██████████| 2/2 [00:00<00:00, 332.24it/s]\n"]}],"source":["create_classification_file([train_0,train_1],[0,1], train_out)\n","create_classification_file([test_0,test_1],[0,1], test_out)\n","create_classification_file([dev_0,dev_1],[0,1], dev_out)"]},{"cell_type":"code","source":["!python /content/drive/MyDrive/transformer-drg-style-transfer-master/run_classifier.py --data_dir \"/content/drive/MyDrive/transformer-drg-style-transfer-master/data/imagecaption/bert_classifier_training\" --bert_model bert-base-uncased --cache_dir '/content/drive/MyDrive/transformer-drg-style-transfer-master' --task_name \"yelp\" --output_dir \"/content/drive/MyDrive/transformer-drg-style-transfer-master/ImageCaptionOutput\" --do_train --num_train_epochs=1 --train_batch_size=32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5GGgEkPfBKit","executionInfo":{"status":"ok","timestamp":1681681368115,"user_tz":420,"elapsed":331055,"user":{"displayName":"Riya Tasgaonkar","userId":"15945572355651300701"}},"outputId":"b701d287-8915-45fc-ca05-da3f9b0d7d39"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","04/16/2023 21:37:18 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","04/16/2023 21:37:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/16/2023 21:37:18 - INFO - __main__ -   Looking at /content/drive/MyDrive/transformer-drg-style-transfer-master/data/imagecaption/bert_classifier_training\n","04/16/2023 21:37:18 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /content/drive/MyDrive/transformer-drg-style-transfer-master/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","04/16/2023 21:37:18 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /content/drive/MyDrive/transformer-drg-style-transfer-master/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpcr2uvk5z\n","04/16/2023 21:37:22 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","04/16/2023 21:37:26 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","04/16/2023 21:37:26 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","04/16/2023 21:37:28 - INFO - __main__ -   *** Example ***\n","04/16/2023 21:37:28 - INFO - __main__ -   guid: train-0\n","04/16/2023 21:37:28 - INFO - __main__ -   tokens: [CLS] young people practice walking on the high wire for the first time . [SEP]\n","04/16/2023 21:37:28 - INFO - __main__ -   input_ids: 101 2402 2111 3218 3788 2006 1996 2152 7318 2005 1996 2034 2051 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   label: 0 (id = 0)\n","04/16/2023 21:37:28 - INFO - __main__ -   *** Example ***\n","04/16/2023 21:37:28 - INFO - __main__ -   guid: train-1\n","04/16/2023 21:37:28 - INFO - __main__ -   tokens: [CLS] a woman and a dog sit on a tree stump wondering why cats have 9 lives . [SEP]\n","04/16/2023 21:37:28 - INFO - __main__ -   input_ids: 101 1037 2450 1998 1037 3899 4133 2006 1037 3392 22475 6603 2339 8870 2031 1023 3268 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   label: 0 (id = 0)\n","04/16/2023 21:37:28 - INFO - __main__ -   *** Example ***\n","04/16/2023 21:37:28 - INFO - __main__ -   guid: train-2\n","04/16/2023 21:37:28 - INFO - __main__ -   tokens: [CLS] the brown dog eats from a bowl on table as a black dog jumps off for grass landing . [SEP]\n","04/16/2023 21:37:28 - INFO - __main__ -   input_ids: 101 1996 2829 3899 20323 2013 1037 4605 2006 2795 2004 1037 2304 3899 14523 2125 2005 5568 4899 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   label: 0 (id = 0)\n","04/16/2023 21:37:28 - INFO - __main__ -   *** Example ***\n","04/16/2023 21:37:28 - INFO - __main__ -   guid: train-3\n","04/16/2023 21:37:28 - INFO - __main__ -   tokens: [CLS] child standing on sp ##rin ##kle ##r mat with spraying is trying to turn water off . [SEP]\n","04/16/2023 21:37:28 - INFO - __main__ -   input_ids: 101 2775 3061 2006 11867 6657 19099 2099 13523 2007 29035 2003 2667 2000 2735 2300 2125 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   label: 0 (id = 0)\n","04/16/2023 21:37:28 - INFO - __main__ -   *** Example ***\n","04/16/2023 21:37:28 - INFO - __main__ -   guid: train-4\n","04/16/2023 21:37:28 - INFO - __main__ -   tokens: [CLS] a man in bull ##fighting regal ##ia rides a bull ' s back with fear . [SEP]\n","04/16/2023 21:37:28 - INFO - __main__ -   input_ids: 101 1037 2158 1999 7087 22158 21279 2401 12271 1037 7087 1005 1055 2067 2007 3571 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","04/16/2023 21:37:28 - INFO - __main__ -   label: 0 (id = 0)\n","04/16/2023 21:37:29 - INFO - __main__ -   ***** Running training *****\n","04/16/2023 21:37:29 - INFO - __main__ -     Num examples = 12000\n","04/16/2023 21:37:29 - INFO - __main__ -     Batch size = 32\n","04/16/2023 21:37:29 - INFO - __main__ -     Num steps = 375\n","Epoch:   0% 0/1 [00:00<?, ?it/s]\n","Iteration:   0% 0/375 [00:00<?, ?it/s]\u001b[A/content/drive/MyDrive/transformer-drg-style-transfer-master/pytorch_pretrained_bert/optimization.py:132: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","\n","Training loss: 8.78e-01 lr: 0.00e+00:   0% 1/375 [00:01<08:47,  1.41s/it]\u001b[A\n","Training loss: 8.33e-01 lr: 1.33e-06:   1% 2/375 [00:02<06:27,  1.04s/it]\u001b[A\n","Training loss: 8.07e-01 lr: 2.67e-06:   1% 3/375 [00:02<05:43,  1.08it/s]\u001b[A\n","Training loss: 7.76e-01 lr: 4.00e-06:   1% 4/375 [00:03<05:22,  1.15it/s]\u001b[A\n","Training loss: 7.50e-01 lr: 5.33e-06:   1% 5/375 [00:04<05:11,  1.19it/s]\u001b[A\n","Training loss: 7.42e-01 lr: 6.67e-06:   2% 6/375 [00:05<05:03,  1.21it/s]\u001b[A\n","Training loss: 7.33e-01 lr: 8.00e-06:   2% 7/375 [00:06<05:23,  1.14it/s]\u001b[A\n","Training loss: 7.27e-01 lr: 9.33e-06:   2% 8/375 [00:07<05:25,  1.13it/s]\u001b[A\n","Training loss: 7.12e-01 lr: 1.07e-05:   2% 9/375 [00:08<05:34,  1.09it/s]\u001b[A\n","Training loss: 7.03e-01 lr: 1.20e-05:   3% 10/375 [00:09<05:21,  1.13it/s]\u001b[A\n","Training loss: 6.99e-01 lr: 1.33e-05:   3% 11/375 [00:09<05:11,  1.17it/s]\u001b[A\n","Training loss: 6.89e-01 lr: 1.47e-05:   3% 12/375 [00:10<05:03,  1.20it/s]\u001b[A\n","Training loss: 6.94e-01 lr: 1.60e-05:   3% 13/375 [00:11<04:58,  1.21it/s]\u001b[A\n","Training loss: 6.75e-01 lr: 1.73e-05:   4% 14/375 [00:12<04:54,  1.23it/s]\u001b[A\n","Training loss: 6.80e-01 lr: 1.87e-05:   4% 15/375 [00:12<04:51,  1.24it/s]\u001b[A\n","Training loss: 6.77e-01 lr: 2.00e-05:   4% 16/375 [00:13<04:49,  1.24it/s]\u001b[A\n","Training loss: 6.67e-01 lr: 2.13e-05:   5% 17/375 [00:14<04:47,  1.24it/s]\u001b[A\n","Training loss: 6.66e-01 lr: 2.27e-05:   5% 18/375 [00:15<04:46,  1.24it/s]\u001b[A\n","Training loss: 6.52e-01 lr: 2.40e-05:   5% 19/375 [00:16<04:45,  1.25it/s]\u001b[A\n","Training loss: 6.45e-01 lr: 2.53e-05:   5% 20/375 [00:16<04:44,  1.25it/s]\u001b[A\n","Training loss: 6.55e-01 lr: 2.67e-05:   6% 21/375 [00:17<04:44,  1.25it/s]\u001b[A\n","Training loss: 6.31e-01 lr: 2.80e-05:   6% 22/375 [00:18<04:43,  1.24it/s]\u001b[A\n","Training loss: 6.07e-01 lr: 2.93e-05:   6% 23/375 [00:19<04:43,  1.24it/s]\u001b[A\n","Training loss: 6.02e-01 lr: 3.07e-05:   6% 24/375 [00:20<04:45,  1.23it/s]\u001b[A\n","Training loss: 6.30e-01 lr: 3.20e-05:   7% 25/375 [00:21<04:46,  1.22it/s]\u001b[A\n","Training loss: 6.02e-01 lr: 3.33e-05:   7% 26/375 [00:21<04:47,  1.21it/s]\u001b[A\n","Training loss: 6.87e-01 lr: 3.47e-05:   7% 27/375 [00:22<04:47,  1.21it/s]\u001b[A\n","Training loss: 6.05e-01 lr: 3.60e-05:   7% 28/375 [00:23<04:44,  1.22it/s]\u001b[A\n","Training loss: 6.14e-01 lr: 3.73e-05:   8% 29/375 [00:24<04:42,  1.22it/s]\u001b[A\n","Training loss: 5.63e-01 lr: 3.87e-05:   8% 30/375 [00:25<04:41,  1.23it/s]\u001b[A\n","Training loss: 5.57e-01 lr: 4.00e-05:   8% 31/375 [00:26<04:41,  1.22it/s]\u001b[A\n","Training loss: 5.12e-01 lr: 4.13e-05:   9% 32/375 [00:26<04:39,  1.23it/s]\u001b[A\n","Training loss: 5.78e-01 lr: 4.27e-05:   9% 33/375 [00:27<04:38,  1.23it/s]\u001b[A\n","Training loss: 5.28e-01 lr: 4.40e-05:   9% 34/375 [00:28<04:38,  1.23it/s]\u001b[A\n","Training loss: 5.47e-01 lr: 4.53e-05:   9% 35/375 [00:29<04:37,  1.22it/s]\u001b[A\n","Training loss: 5.20e-01 lr: 4.67e-05:  10% 36/375 [00:30<04:38,  1.22it/s]\u001b[A\n","Training loss: 5.71e-01 lr: 4.80e-05:  10% 37/375 [00:30<04:37,  1.22it/s]\u001b[A\n","Training loss: 5.96e-01 lr: 4.93e-05:  10% 38/375 [00:31<04:36,  1.22it/s]\u001b[A\n","Training loss: 5.91e-01 lr: 4.49e-05:  10% 39/375 [00:32<04:35,  1.22it/s]\u001b[A\n","Training loss: 5.65e-01 lr: 4.48e-05:  11% 40/375 [00:33<04:38,  1.20it/s]\u001b[A\n","Training loss: 5.80e-01 lr: 4.47e-05:  11% 41/375 [00:34<04:38,  1.20it/s]\u001b[A\n","Training loss: 5.72e-01 lr: 4.45e-05:  11% 42/375 [00:35<04:38,  1.20it/s]\u001b[A\n","Training loss: 5.89e-01 lr: 4.44e-05:  11% 43/375 [00:35<04:38,  1.19it/s]\u001b[A\n","Training loss: 6.23e-01 lr: 4.43e-05:  12% 44/375 [00:36<04:37,  1.19it/s]\u001b[A\n","Training loss: 6.16e-01 lr: 4.41e-05:  12% 45/375 [00:37<04:35,  1.20it/s]\u001b[A\n","Training loss: 5.86e-01 lr: 4.40e-05:  12% 46/375 [00:38<04:34,  1.20it/s]\u001b[A\n","Training loss: 5.56e-01 lr: 4.39e-05:  13% 47/375 [00:39<04:34,  1.20it/s]\u001b[A\n","Training loss: 5.48e-01 lr: 4.37e-05:  13% 48/375 [00:40<04:32,  1.20it/s]\u001b[A\n","Training loss: 5.46e-01 lr: 4.36e-05:  13% 49/375 [00:40<04:31,  1.20it/s]\u001b[A\n","Training loss: 5.57e-01 lr: 4.35e-05:  13% 50/375 [00:41<04:31,  1.20it/s]\u001b[A\n","Training loss: 5.36e-01 lr: 4.33e-05:  14% 51/375 [00:42<04:29,  1.20it/s]\u001b[A\n","Training loss: 5.17e-01 lr: 4.32e-05:  14% 52/375 [00:43<04:30,  1.20it/s]\u001b[A\n","Training loss: 5.20e-01 lr: 4.31e-05:  14% 53/375 [00:44<04:28,  1.20it/s]\u001b[A\n","Training loss: 5.01e-01 lr: 4.29e-05:  14% 54/375 [00:45<04:28,  1.20it/s]\u001b[A\n","Training loss: 5.19e-01 lr: 4.28e-05:  15% 55/375 [00:45<04:27,  1.20it/s]\u001b[A\n","Training loss: 5.45e-01 lr: 4.27e-05:  15% 56/375 [00:46<04:29,  1.18it/s]\u001b[A\n","Training loss: 5.40e-01 lr: 4.25e-05:  15% 57/375 [00:47<04:30,  1.18it/s]\u001b[A\n","Training loss: 5.49e-01 lr: 4.24e-05:  15% 58/375 [00:48<04:29,  1.18it/s]\u001b[A\n","Training loss: 4.98e-01 lr: 4.23e-05:  16% 59/375 [00:49<04:30,  1.17it/s]\u001b[A\n","Training loss: 4.89e-01 lr: 4.21e-05:  16% 60/375 [00:50<04:31,  1.16it/s]\u001b[A\n","Training loss: 4.58e-01 lr: 4.20e-05:  16% 61/375 [00:51<04:28,  1.17it/s]\u001b[A\n","Training loss: 4.92e-01 lr: 4.19e-05:  17% 62/375 [00:51<04:27,  1.17it/s]\u001b[A\n","Training loss: 4.48e-01 lr: 4.17e-05:  17% 63/375 [00:52<04:25,  1.18it/s]\u001b[A\n","Training loss: 4.90e-01 lr: 4.16e-05:  17% 64/375 [00:53<04:23,  1.18it/s]\u001b[A\n","Training loss: 5.15e-01 lr: 4.15e-05:  17% 65/375 [00:54<04:23,  1.18it/s]\u001b[A\n","Training loss: 4.83e-01 lr: 4.13e-05:  18% 66/375 [00:55<04:21,  1.18it/s]\u001b[A\n","Training loss: 5.26e-01 lr: 4.12e-05:  18% 67/375 [00:56<04:21,  1.18it/s]\u001b[A\n","Training loss: 4.60e-01 lr: 4.11e-05:  18% 68/375 [00:57<04:20,  1.18it/s]\u001b[A\n","Training loss: 5.27e-01 lr: 4.09e-05:  18% 69/375 [00:57<04:19,  1.18it/s]\u001b[A\n","Training loss: 4.90e-01 lr: 4.08e-05:  19% 70/375 [00:58<04:20,  1.17it/s]\u001b[A\n","Training loss: 5.06e-01 lr: 4.07e-05:  19% 71/375 [00:59<04:18,  1.18it/s]\u001b[A\n","Training loss: 5.09e-01 lr: 4.05e-05:  19% 72/375 [01:00<04:20,  1.16it/s]\u001b[A\n","Training loss: 5.08e-01 lr: 4.04e-05:  19% 73/375 [01:01<04:19,  1.16it/s]\u001b[A\n","Training loss: 5.03e-01 lr: 4.03e-05:  20% 74/375 [01:02<04:19,  1.16it/s]\u001b[A\n","Training loss: 5.14e-01 lr: 4.01e-05:  20% 75/375 [01:03<04:18,  1.16it/s]\u001b[A\n","Training loss: 5.57e-01 lr: 4.00e-05:  20% 76/375 [01:03<04:18,  1.16it/s]\u001b[A\n","Training loss: 5.57e-01 lr: 3.99e-05:  21% 77/375 [01:04<04:15,  1.17it/s]\u001b[A\n","Training loss: 5.39e-01 lr: 3.97e-05:  21% 78/375 [01:05<04:13,  1.17it/s]\u001b[A\n","Training loss: 5.22e-01 lr: 3.96e-05:  21% 79/375 [01:06<04:11,  1.18it/s]\u001b[A\n","Training loss: 5.73e-01 lr: 3.95e-05:  21% 80/375 [01:07<04:09,  1.18it/s]\u001b[A\n","Training loss: 5.69e-01 lr: 3.93e-05:  22% 81/375 [01:08<04:08,  1.18it/s]\u001b[A\n","Training loss: 5.70e-01 lr: 3.92e-05:  22% 82/375 [01:08<04:07,  1.19it/s]\u001b[A\n","Training loss: 5.38e-01 lr: 3.91e-05:  22% 83/375 [01:09<04:05,  1.19it/s]\u001b[A\n","Training loss: 5.04e-01 lr: 3.89e-05:  22% 84/375 [01:10<04:04,  1.19it/s]\u001b[A\n","Training loss: 5.12e-01 lr: 3.88e-05:  23% 85/375 [01:11<04:03,  1.19it/s]\u001b[A\n","Training loss: 4.75e-01 lr: 3.87e-05:  23% 86/375 [01:12<04:02,  1.19it/s]\u001b[A\n","Training loss: 4.72e-01 lr: 3.85e-05:  23% 87/375 [01:13<04:01,  1.19it/s]\u001b[A\n","Training loss: 4.85e-01 lr: 3.84e-05:  23% 88/375 [01:14<03:59,  1.20it/s]\u001b[A\n","Training loss: 5.32e-01 lr: 3.83e-05:  24% 89/375 [01:14<04:01,  1.19it/s]\u001b[A\n","Training loss: 4.92e-01 lr: 3.81e-05:  24% 90/375 [01:15<04:00,  1.18it/s]\u001b[A\n","Training loss: 5.16e-01 lr: 3.80e-05:  24% 91/375 [01:16<04:00,  1.18it/s]\u001b[A\n","Training loss: 5.09e-01 lr: 3.79e-05:  25% 92/375 [01:17<04:00,  1.18it/s]\u001b[A\n","Training loss: 5.53e-01 lr: 3.77e-05:  25% 93/375 [01:18<03:57,  1.19it/s]\u001b[A\n","Training loss: 5.72e-01 lr: 3.76e-05:  25% 94/375 [01:19<03:56,  1.19it/s]\u001b[A\n","Training loss: 5.85e-01 lr: 3.75e-05:  25% 95/375 [01:19<03:54,  1.20it/s]\u001b[A\n","Training loss: 5.69e-01 lr: 3.73e-05:  26% 96/375 [01:20<03:52,  1.20it/s]\u001b[A\n","Training loss: 5.40e-01 lr: 3.72e-05:  26% 97/375 [01:21<03:51,  1.20it/s]\u001b[A\n","Training loss: 5.49e-01 lr: 3.71e-05:  26% 98/375 [01:22<03:50,  1.20it/s]\u001b[A\n","Training loss: 4.97e-01 lr: 3.69e-05:  26% 99/375 [01:23<03:49,  1.20it/s]\u001b[A\n","Training loss: 5.03e-01 lr: 3.68e-05:  27% 100/375 [01:24<03:47,  1.21it/s]\u001b[A\n","Training loss: 5.23e-01 lr: 3.67e-05:  27% 101/375 [01:24<03:46,  1.21it/s]\u001b[A\n","Training loss: 5.68e-01 lr: 3.65e-05:  27% 102/375 [01:25<03:46,  1.21it/s]\u001b[A\n","Training loss: 6.32e-01 lr: 3.64e-05:  27% 103/375 [01:26<03:45,  1.21it/s]\u001b[A\n","Training loss: 5.92e-01 lr: 3.63e-05:  28% 104/375 [01:27<03:44,  1.20it/s]\u001b[A\n","Training loss: 5.62e-01 lr: 3.61e-05:  28% 105/375 [01:28<03:48,  1.18it/s]\u001b[A\n","Training loss: 5.26e-01 lr: 3.60e-05:  28% 106/375 [01:29<03:47,  1.18it/s]\u001b[A\n","Training loss: 5.18e-01 lr: 3.59e-05:  29% 107/375 [01:29<03:46,  1.18it/s]\u001b[A\n","Training loss: 5.51e-01 lr: 3.57e-05:  29% 108/375 [01:30<03:45,  1.18it/s]\u001b[A\n","Training loss: 5.52e-01 lr: 3.56e-05:  29% 109/375 [01:31<03:42,  1.20it/s]\u001b[A\n","Training loss: 5.14e-01 lr: 3.55e-05:  29% 110/375 [01:32<03:40,  1.20it/s]\u001b[A\n","Training loss: 4.82e-01 lr: 3.53e-05:  30% 111/375 [01:33<03:38,  1.21it/s]\u001b[A\n","Training loss: 4.77e-01 lr: 3.52e-05:  30% 112/375 [01:34<03:36,  1.21it/s]\u001b[A\n","Training loss: 4.91e-01 lr: 3.51e-05:  30% 113/375 [01:34<03:35,  1.22it/s]\u001b[A\n","Training loss: 4.84e-01 lr: 3.49e-05:  30% 114/375 [01:35<03:34,  1.22it/s]\u001b[A\n","Training loss: 5.20e-01 lr: 3.48e-05:  31% 115/375 [01:36<03:33,  1.22it/s]\u001b[A\n","Training loss: 5.19e-01 lr: 3.47e-05:  31% 116/375 [01:37<03:32,  1.22it/s]\u001b[A\n","Training loss: 5.00e-01 lr: 3.45e-05:  31% 117/375 [01:38<03:31,  1.22it/s]\u001b[A\n","Training loss: 4.45e-01 lr: 3.44e-05:  31% 118/375 [01:38<03:31,  1.21it/s]\u001b[A\n","Training loss: 4.19e-01 lr: 3.43e-05:  32% 119/375 [01:39<03:29,  1.22it/s]\u001b[A\n","Training loss: 4.38e-01 lr: 3.41e-05:  32% 120/375 [01:40<03:29,  1.22it/s]\u001b[A\n","Training loss: 4.29e-01 lr: 3.40e-05:  32% 121/375 [01:41<03:30,  1.21it/s]\u001b[A\n","Training loss: 4.95e-01 lr: 3.39e-05:  33% 122/375 [01:42<03:30,  1.20it/s]\u001b[A\n","Training loss: 4.64e-01 lr: 3.37e-05:  33% 123/375 [01:43<03:29,  1.20it/s]\u001b[A\n","Training loss: 4.64e-01 lr: 3.36e-05:  33% 124/375 [01:43<03:29,  1.20it/s]\u001b[A\n","Training loss: 4.54e-01 lr: 3.35e-05:  33% 125/375 [01:44<03:30,  1.19it/s]\u001b[A\n","Training loss: 4.54e-01 lr: 3.33e-05:  34% 126/375 [01:45<03:27,  1.20it/s]\u001b[A\n","Training loss: 4.75e-01 lr: 3.32e-05:  34% 127/375 [01:46<03:25,  1.20it/s]\u001b[A\n","Training loss: 4.48e-01 lr: 3.31e-05:  34% 128/375 [01:47<03:23,  1.21it/s]\u001b[A\n","Training loss: 4.31e-01 lr: 3.29e-05:  34% 129/375 [01:48<03:23,  1.21it/s]\u001b[A\n","Training loss: 4.42e-01 lr: 3.28e-05:  35% 130/375 [01:48<03:21,  1.22it/s]\u001b[A\n","Training loss: 4.35e-01 lr: 3.27e-05:  35% 131/375 [01:49<03:20,  1.22it/s]\u001b[A\n","Training loss: 4.75e-01 lr: 3.25e-05:  35% 132/375 [01:50<03:19,  1.22it/s]\u001b[A\n","Training loss: 4.60e-01 lr: 3.24e-05:  35% 133/375 [01:51<03:19,  1.22it/s]\u001b[A\n","Training loss: 4.24e-01 lr: 3.23e-05:  36% 134/375 [01:52<03:17,  1.22it/s]\u001b[A\n","Training loss: 4.36e-01 lr: 3.21e-05:  36% 135/375 [01:53<03:17,  1.22it/s]\u001b[A\n","Training loss: 3.94e-01 lr: 3.20e-05:  36% 136/375 [01:53<03:15,  1.22it/s]\u001b[A\n","Training loss: 3.61e-01 lr: 3.19e-05:  37% 137/375 [01:54<03:15,  1.22it/s]\u001b[A\n","Training loss: 3.91e-01 lr: 3.17e-05:  37% 138/375 [01:55<03:15,  1.21it/s]\u001b[A\n","Training loss: 3.81e-01 lr: 3.16e-05:  37% 139/375 [01:56<03:16,  1.20it/s]\u001b[A\n","Training loss: 3.83e-01 lr: 3.15e-05:  37% 140/375 [01:57<03:16,  1.20it/s]\u001b[A\n","Training loss: 3.80e-01 lr: 3.13e-05:  38% 141/375 [01:58<03:16,  1.19it/s]\u001b[A\n","Training loss: 4.22e-01 lr: 3.12e-05:  38% 142/375 [01:58<03:14,  1.20it/s]\u001b[A\n","Training loss: 4.40e-01 lr: 3.11e-05:  38% 143/375 [01:59<03:13,  1.20it/s]\u001b[A\n","Training loss: 4.31e-01 lr: 3.09e-05:  38% 144/375 [02:00<03:11,  1.20it/s]\u001b[A\n","Training loss: 4.50e-01 lr: 3.08e-05:  39% 145/375 [02:01<03:10,  1.21it/s]\u001b[A\n","Training loss: 4.40e-01 lr: 3.07e-05:  39% 146/375 [02:02<03:09,  1.21it/s]\u001b[A\n","Training loss: 4.67e-01 lr: 3.05e-05:  39% 147/375 [02:02<03:08,  1.21it/s]\u001b[A\n","Training loss: 4.37e-01 lr: 3.04e-05:  39% 148/375 [02:03<03:07,  1.21it/s]\u001b[A\n","Training loss: 4.18e-01 lr: 3.03e-05:  40% 149/375 [02:04<03:06,  1.21it/s]\u001b[A\n","Training loss: 4.12e-01 lr: 3.01e-05:  40% 150/375 [02:05<03:06,  1.21it/s]\u001b[A\n","Training loss: 4.76e-01 lr: 3.00e-05:  40% 151/375 [02:06<03:04,  1.21it/s]\u001b[A\n","Training loss: 5.15e-01 lr: 2.99e-05:  41% 152/375 [02:07<03:04,  1.21it/s]\u001b[A\n","Training loss: 5.27e-01 lr: 2.97e-05:  41% 153/375 [02:07<03:03,  1.21it/s]\u001b[A\n","Training loss: 5.16e-01 lr: 2.96e-05:  41% 154/375 [02:08<03:04,  1.20it/s]\u001b[A\n","Training loss: 5.37e-01 lr: 2.95e-05:  41% 155/375 [02:09<03:04,  1.19it/s]\u001b[A\n","Training loss: 5.24e-01 lr: 2.93e-05:  42% 156/375 [02:10<03:03,  1.19it/s]\u001b[A\n","Training loss: 5.13e-01 lr: 2.92e-05:  42% 157/375 [02:11<03:03,  1.19it/s]\u001b[A\n","Training loss: 5.06e-01 lr: 2.91e-05:  42% 158/375 [02:12<03:02,  1.19it/s]\u001b[A\n","Training loss: 5.03e-01 lr: 2.89e-05:  42% 159/375 [02:13<03:00,  1.20it/s]\u001b[A\n","Training loss: 4.68e-01 lr: 2.88e-05:  43% 160/375 [02:13<02:59,  1.19it/s]\u001b[A\n","Training loss: 4.73e-01 lr: 2.87e-05:  43% 161/375 [02:14<02:58,  1.20it/s]\u001b[A\n","Training loss: 4.45e-01 lr: 2.85e-05:  43% 162/375 [02:15<02:57,  1.20it/s]\u001b[A\n","Training loss: 4.78e-01 lr: 2.84e-05:  43% 163/375 [02:16<02:56,  1.20it/s]\u001b[A\n","Training loss: 4.69e-01 lr: 2.83e-05:  44% 164/375 [02:17<02:55,  1.20it/s]\u001b[A\n","Training loss: 4.88e-01 lr: 2.81e-05:  44% 165/375 [02:18<02:54,  1.20it/s]\u001b[A\n","Training loss: 4.88e-01 lr: 2.80e-05:  44% 166/375 [02:18<02:53,  1.21it/s]\u001b[A\n","Training loss: 4.82e-01 lr: 2.79e-05:  45% 167/375 [02:19<02:52,  1.21it/s]\u001b[A\n","Training loss: 4.58e-01 lr: 2.77e-05:  45% 168/375 [02:20<02:51,  1.20it/s]\u001b[A\n","Training loss: 3.99e-01 lr: 2.76e-05:  45% 169/375 [02:21<02:50,  1.20it/s]\u001b[A\n","Training loss: 4.44e-01 lr: 2.75e-05:  45% 170/375 [02:22<02:50,  1.20it/s]\u001b[A\n","Training loss: 4.42e-01 lr: 2.73e-05:  46% 171/375 [02:23<02:51,  1.19it/s]\u001b[A\n","Training loss: 4.19e-01 lr: 2.72e-05:  46% 172/375 [02:23<02:50,  1.19it/s]\u001b[A\n","Training loss: 4.37e-01 lr: 2.71e-05:  46% 173/375 [02:24<02:50,  1.18it/s]\u001b[A\n","Training loss: 4.64e-01 lr: 2.69e-05:  46% 174/375 [02:25<02:50,  1.18it/s]\u001b[A\n","Training loss: 4.35e-01 lr: 2.68e-05:  47% 175/375 [02:26<02:48,  1.19it/s]\u001b[A\n","Training loss: 4.64e-01 lr: 2.67e-05:  47% 176/375 [02:27<02:47,  1.19it/s]\u001b[A\n","Training loss: 4.89e-01 lr: 2.65e-05:  47% 177/375 [02:28<02:46,  1.19it/s]\u001b[A\n","Training loss: 4.58e-01 lr: 2.64e-05:  47% 178/375 [02:28<02:44,  1.20it/s]\u001b[A\n","Training loss: 4.18e-01 lr: 2.63e-05:  48% 179/375 [02:29<02:44,  1.19it/s]\u001b[A\n","Training loss: 4.58e-01 lr: 2.61e-05:  48% 180/375 [02:30<02:42,  1.20it/s]\u001b[A\n","Training loss: 5.09e-01 lr: 2.60e-05:  48% 181/375 [02:31<02:42,  1.19it/s]\u001b[A\n","Training loss: 5.18e-01 lr: 2.59e-05:  49% 182/375 [02:32<02:41,  1.20it/s]\u001b[A\n","Training loss: 5.24e-01 lr: 2.57e-05:  49% 183/375 [02:33<02:40,  1.20it/s]\u001b[A\n","Training loss: 5.05e-01 lr: 2.56e-05:  49% 184/375 [02:33<02:39,  1.20it/s]\u001b[A\n","Training loss: 5.11e-01 lr: 2.55e-05:  49% 185/375 [02:34<02:38,  1.20it/s]\u001b[A\n","Training loss: 5.22e-01 lr: 2.53e-05:  50% 186/375 [02:35<02:37,  1.20it/s]\u001b[A\n","Training loss: 4.96e-01 lr: 2.52e-05:  50% 187/375 [02:36<02:37,  1.19it/s]\u001b[A\n","Training loss: 4.77e-01 lr: 2.51e-05:  50% 188/375 [02:37<02:37,  1.19it/s]\u001b[A\n","Training loss: 5.10e-01 lr: 2.49e-05:  50% 189/375 [02:38<02:37,  1.18it/s]\u001b[A\n","Training loss: 5.06e-01 lr: 2.48e-05:  51% 190/375 [02:38<02:36,  1.18it/s]\u001b[A\n","Training loss: 4.70e-01 lr: 2.47e-05:  51% 191/375 [02:39<02:34,  1.19it/s]\u001b[A\n","Training loss: 4.90e-01 lr: 2.45e-05:  51% 192/375 [02:40<02:34,  1.19it/s]\u001b[A\n","Training loss: 4.30e-01 lr: 2.44e-05:  51% 193/375 [02:41<02:32,  1.19it/s]\u001b[A\n","Training loss: 4.41e-01 lr: 2.43e-05:  52% 194/375 [02:42<02:31,  1.20it/s]\u001b[A\n","Training loss: 4.50e-01 lr: 2.41e-05:  52% 195/375 [02:43<02:30,  1.20it/s]\u001b[A\n","Training loss: 4.29e-01 lr: 2.40e-05:  52% 196/375 [02:43<02:29,  1.20it/s]\u001b[A\n","Training loss: 4.40e-01 lr: 2.39e-05:  53% 197/375 [02:44<02:28,  1.20it/s]\u001b[A\n","Training loss: 4.37e-01 lr: 2.37e-05:  53% 198/375 [02:45<02:27,  1.20it/s]\u001b[A\n","Training loss: 4.00e-01 lr: 2.36e-05:  53% 199/375 [02:46<02:26,  1.20it/s]\u001b[A\n","Training loss: 4.22e-01 lr: 2.35e-05:  53% 200/375 [02:47<02:25,  1.20it/s]\u001b[A\n","Training loss: 4.37e-01 lr: 2.33e-05:  54% 201/375 [02:48<02:24,  1.20it/s]\u001b[A\n","Training loss: 4.24e-01 lr: 2.32e-05:  54% 202/375 [02:48<02:23,  1.21it/s]\u001b[A\n","Training loss: 3.96e-01 lr: 2.31e-05:  54% 203/375 [02:49<02:23,  1.20it/s]\u001b[A\n","Training loss: 4.44e-01 lr: 2.29e-05:  54% 204/375 [02:50<02:24,  1.19it/s]\u001b[A\n","Training loss: 4.00e-01 lr: 2.28e-05:  55% 205/375 [02:51<02:22,  1.19it/s]\u001b[A\n","Training loss: 4.70e-01 lr: 2.27e-05:  55% 206/375 [02:52<02:22,  1.19it/s]\u001b[A\n","Training loss: 4.41e-01 lr: 2.25e-05:  55% 207/375 [02:53<02:20,  1.20it/s]\u001b[A\n","Training loss: 4.51e-01 lr: 2.24e-05:  55% 208/375 [02:53<02:19,  1.20it/s]\u001b[A\n","Training loss: 4.46e-01 lr: 2.23e-05:  56% 209/375 [02:54<02:18,  1.20it/s]\u001b[A\n","Training loss: 4.34e-01 lr: 2.21e-05:  56% 210/375 [02:55<02:17,  1.20it/s]\u001b[A\n","Training loss: 4.45e-01 lr: 2.20e-05:  56% 211/375 [02:56<02:16,  1.20it/s]\u001b[A\n","Training loss: 4.03e-01 lr: 2.19e-05:  57% 212/375 [02:57<02:15,  1.20it/s]\u001b[A\n","Training loss: 4.24e-01 lr: 2.17e-05:  57% 213/375 [02:58<02:14,  1.21it/s]\u001b[A\n","Training loss: 4.05e-01 lr: 2.16e-05:  57% 214/375 [02:58<02:14,  1.20it/s]\u001b[A\n","Training loss: 4.02e-01 lr: 2.15e-05:  57% 215/375 [02:59<02:13,  1.20it/s]\u001b[A\n","Training loss: 4.51e-01 lr: 2.13e-05:  58% 216/375 [03:00<02:11,  1.21it/s]\u001b[A\n","Training loss: 4.70e-01 lr: 2.12e-05:  58% 217/375 [03:01<02:11,  1.20it/s]\u001b[A\n","Training loss: 4.37e-01 lr: 2.11e-05:  58% 218/375 [03:02<02:10,  1.21it/s]\u001b[A\n","Training loss: 3.99e-01 lr: 2.09e-05:  58% 219/375 [03:03<02:10,  1.19it/s]\u001b[A\n","Training loss: 3.83e-01 lr: 2.08e-05:  59% 220/375 [03:03<02:10,  1.19it/s]\u001b[A\n","Training loss: 4.25e-01 lr: 2.07e-05:  59% 221/375 [03:04<02:09,  1.19it/s]\u001b[A\n","Training loss: 4.33e-01 lr: 2.05e-05:  59% 222/375 [03:05<02:08,  1.19it/s]\u001b[A\n","Training loss: 5.08e-01 lr: 2.04e-05:  59% 223/375 [03:06<02:07,  1.19it/s]\u001b[A\n","Training loss: 5.13e-01 lr: 2.03e-05:  60% 224/375 [03:07<02:06,  1.20it/s]\u001b[A\n","Training loss: 4.51e-01 lr: 2.01e-05:  60% 225/375 [03:08<02:04,  1.20it/s]\u001b[A\n","Training loss: 4.66e-01 lr: 2.00e-05:  60% 226/375 [03:09<02:03,  1.20it/s]\u001b[A\n","Training loss: 4.31e-01 lr: 1.99e-05:  61% 227/375 [03:09<02:02,  1.20it/s]\u001b[A\n","Training loss: 4.09e-01 lr: 1.97e-05:  61% 228/375 [03:10<02:01,  1.21it/s]\u001b[A\n","Training loss: 4.14e-01 lr: 1.96e-05:  61% 229/375 [03:11<02:00,  1.21it/s]\u001b[A\n","Training loss: 4.31e-01 lr: 1.95e-05:  61% 230/375 [03:12<01:59,  1.21it/s]\u001b[A\n","Training loss: 4.14e-01 lr: 1.93e-05:  62% 231/375 [03:13<01:59,  1.21it/s]\u001b[A\n","Training loss: 4.46e-01 lr: 1.92e-05:  62% 232/375 [03:13<01:58,  1.21it/s]\u001b[A\n","Training loss: 4.70e-01 lr: 1.91e-05:  62% 233/375 [03:14<01:57,  1.21it/s]\u001b[A\n","Training loss: 4.41e-01 lr: 1.89e-05:  62% 234/375 [03:15<01:56,  1.21it/s]\u001b[A\n","Training loss: 4.57e-01 lr: 1.88e-05:  63% 235/375 [03:16<01:55,  1.21it/s]\u001b[A\n","Training loss: 4.91e-01 lr: 1.87e-05:  63% 236/375 [03:17<01:56,  1.20it/s]\u001b[A\n","Training loss: 4.74e-01 lr: 1.85e-05:  63% 237/375 [03:18<01:55,  1.20it/s]\u001b[A\n","Training loss: 6.02e-01 lr: 1.84e-05:  63% 238/375 [03:18<01:54,  1.19it/s]\u001b[A\n","Training loss: 5.80e-01 lr: 1.83e-05:  64% 239/375 [03:19<01:54,  1.19it/s]\u001b[A\n","Training loss: 5.40e-01 lr: 1.81e-05:  64% 240/375 [03:20<01:52,  1.20it/s]\u001b[A\n","Training loss: 5.38e-01 lr: 1.80e-05:  64% 241/375 [03:21<01:51,  1.20it/s]\u001b[A\n","Training loss: 5.21e-01 lr: 1.79e-05:  65% 242/375 [03:22<01:50,  1.21it/s]\u001b[A\n","Training loss: 5.11e-01 lr: 1.77e-05:  65% 243/375 [03:23<01:49,  1.21it/s]\u001b[A\n","Training loss: 4.98e-01 lr: 1.76e-05:  65% 244/375 [03:23<01:48,  1.21it/s]\u001b[A\n","Training loss: 4.80e-01 lr: 1.75e-05:  65% 245/375 [03:24<01:47,  1.21it/s]\u001b[A\n","Training loss: 4.69e-01 lr: 1.73e-05:  66% 246/375 [03:25<01:46,  1.21it/s]\u001b[A\n","Training loss: 4.79e-01 lr: 1.72e-05:  66% 247/375 [03:26<01:45,  1.21it/s]\u001b[A\n","Training loss: 4.82e-01 lr: 1.71e-05:  66% 248/375 [03:27<01:44,  1.21it/s]\u001b[A\n","Training loss: 5.15e-01 lr: 1.69e-05:  66% 249/375 [03:28<01:44,  1.21it/s]\u001b[A\n","Training loss: 4.82e-01 lr: 1.68e-05:  67% 250/375 [03:28<01:43,  1.21it/s]\u001b[A\n","Training loss: 4.49e-01 lr: 1.67e-05:  67% 251/375 [03:29<01:42,  1.21it/s]\u001b[A\n","Training loss: 4.18e-01 lr: 1.65e-05:  67% 252/375 [03:30<01:42,  1.20it/s]\u001b[A\n","Training loss: 3.90e-01 lr: 1.64e-05:  67% 253/375 [03:31<01:42,  1.19it/s]\u001b[A\n","Training loss: 3.96e-01 lr: 1.63e-05:  68% 254/375 [03:32<01:41,  1.19it/s]\u001b[A\n","Training loss: 3.61e-01 lr: 1.61e-05:  68% 255/375 [03:33<01:41,  1.18it/s]\u001b[A\n","Training loss: 3.66e-01 lr: 1.60e-05:  68% 256/375 [03:33<01:40,  1.19it/s]\u001b[A\n","Training loss: 4.12e-01 lr: 1.59e-05:  69% 257/375 [03:34<01:38,  1.20it/s]\u001b[A\n","Training loss: 3.88e-01 lr: 1.57e-05:  69% 258/375 [03:35<01:37,  1.20it/s]\u001b[A\n","Training loss: 4.65e-01 lr: 1.56e-05:  69% 259/375 [03:36<01:36,  1.20it/s]\u001b[A\n","Training loss: 4.22e-01 lr: 1.55e-05:  69% 260/375 [03:37<01:35,  1.20it/s]\u001b[A\n","Training loss: 4.33e-01 lr: 1.53e-05:  70% 261/375 [03:38<01:34,  1.21it/s]\u001b[A\n","Training loss: 4.24e-01 lr: 1.52e-05:  70% 262/375 [03:38<01:33,  1.20it/s]\u001b[A\n","Training loss: 3.55e-01 lr: 1.51e-05:  70% 263/375 [03:39<01:33,  1.20it/s]\u001b[A\n","Training loss: 4.19e-01 lr: 1.49e-05:  70% 264/375 [03:40<01:31,  1.21it/s]\u001b[A\n","Training loss: 3.92e-01 lr: 1.48e-05:  71% 265/375 [03:41<01:31,  1.21it/s]\u001b[A\n","Training loss: 3.80e-01 lr: 1.47e-05:  71% 266/375 [03:42<01:30,  1.20it/s]\u001b[A\n","Training loss: 3.81e-01 lr: 1.45e-05:  71% 267/375 [03:43<01:29,  1.21it/s]\u001b[A\n","Training loss: 4.34e-01 lr: 1.44e-05:  71% 268/375 [03:43<01:29,  1.19it/s]\u001b[A\n","Training loss: 3.96e-01 lr: 1.43e-05:  72% 269/375 [03:44<01:28,  1.19it/s]\u001b[A\n","Training loss: 4.00e-01 lr: 1.41e-05:  72% 270/375 [03:45<01:28,  1.19it/s]\u001b[A\n","Training loss: 3.46e-01 lr: 1.40e-05:  72% 271/375 [03:46<01:27,  1.19it/s]\u001b[A\n","Training loss: 4.13e-01 lr: 1.39e-05:  73% 272/375 [03:47<01:26,  1.19it/s]\u001b[A\n","Training loss: 3.88e-01 lr: 1.37e-05:  73% 273/375 [03:48<01:25,  1.20it/s]\u001b[A\n","Training loss: 3.82e-01 lr: 1.36e-05:  73% 274/375 [03:48<01:24,  1.20it/s]\u001b[A\n","Training loss: 3.63e-01 lr: 1.35e-05:  73% 275/375 [03:49<01:23,  1.20it/s]\u001b[A\n","Training loss: 4.21e-01 lr: 1.33e-05:  74% 276/375 [03:50<01:22,  1.20it/s]\u001b[A\n","Training loss: 4.80e-01 lr: 1.32e-05:  74% 277/375 [03:51<01:21,  1.20it/s]\u001b[A\n","Training loss: 4.12e-01 lr: 1.31e-05:  74% 278/375 [03:52<01:20,  1.20it/s]\u001b[A\n","Training loss: 4.11e-01 lr: 1.29e-05:  74% 279/375 [03:53<01:19,  1.20it/s]\u001b[A\n","Training loss: 4.07e-01 lr: 1.28e-05:  75% 280/375 [03:53<01:18,  1.21it/s]\u001b[A\n","Training loss: 4.17e-01 lr: 1.27e-05:  75% 281/375 [03:54<01:18,  1.20it/s]\u001b[A\n","Training loss: 4.19e-01 lr: 1.25e-05:  75% 282/375 [03:55<01:17,  1.21it/s]\u001b[A\n","Training loss: 4.18e-01 lr: 1.24e-05:  75% 283/375 [03:56<01:16,  1.21it/s]\u001b[A\n","Training loss: 4.52e-01 lr: 1.23e-05:  76% 284/375 [03:57<01:15,  1.20it/s]\u001b[A\n","Training loss: 4.66e-01 lr: 1.21e-05:  76% 285/375 [03:58<01:15,  1.20it/s]\u001b[A\n","Training loss: 4.63e-01 lr: 1.20e-05:  76% 286/375 [03:58<01:14,  1.19it/s]\u001b[A\n","Training loss: 4.64e-01 lr: 1.19e-05:  77% 287/375 [03:59<01:14,  1.18it/s]\u001b[A\n","Training loss: 4.73e-01 lr: 1.17e-05:  77% 288/375 [04:00<01:13,  1.18it/s]\u001b[A\n","Training loss: 4.37e-01 lr: 1.16e-05:  77% 289/375 [04:01<01:12,  1.19it/s]\u001b[A\n","Training loss: 4.36e-01 lr: 1.15e-05:  77% 290/375 [04:02<01:11,  1.19it/s]\u001b[A\n","Training loss: 4.21e-01 lr: 1.13e-05:  78% 291/375 [04:03<01:09,  1.20it/s]\u001b[A\n","Training loss: 4.09e-01 lr: 1.12e-05:  78% 292/375 [04:03<01:09,  1.20it/s]\u001b[A\n","Training loss: 4.00e-01 lr: 1.11e-05:  78% 293/375 [04:04<01:08,  1.20it/s]\u001b[A\n","Training loss: 4.08e-01 lr: 1.09e-05:  78% 294/375 [04:05<01:07,  1.20it/s]\u001b[A\n","Training loss: 4.19e-01 lr: 1.08e-05:  79% 295/375 [04:06<01:06,  1.20it/s]\u001b[A\n","Training loss: 4.61e-01 lr: 1.07e-05:  79% 296/375 [04:07<01:05,  1.20it/s]\u001b[A\n","Training loss: 4.89e-01 lr: 1.05e-05:  79% 297/375 [04:08<01:04,  1.20it/s]\u001b[A\n","Training loss: 4.94e-01 lr: 1.04e-05:  79% 298/375 [04:08<01:03,  1.20it/s]\u001b[A\n","Training loss: 4.45e-01 lr: 1.03e-05:  80% 299/375 [04:09<01:03,  1.20it/s]\u001b[A\n","Training loss: 4.65e-01 lr: 1.01e-05:  80% 300/375 [04:10<01:02,  1.20it/s]\u001b[A\n","Training loss: 4.94e-01 lr: 1.00e-05:  80% 301/375 [04:11<01:01,  1.20it/s]\u001b[A\n","Training loss: 4.54e-01 lr: 9.87e-06:  81% 302/375 [04:12<01:01,  1.19it/s]\u001b[A\n","Training loss: 4.34e-01 lr: 9.73e-06:  81% 303/375 [04:13<01:00,  1.19it/s]\u001b[A\n","Training loss: 4.81e-01 lr: 9.60e-06:  81% 304/375 [04:13<00:59,  1.19it/s]\u001b[A\n","Training loss: 4.67e-01 lr: 9.47e-06:  81% 305/375 [04:14<00:58,  1.20it/s]\u001b[A\n","Training loss: 4.48e-01 lr: 9.33e-06:  82% 306/375 [04:15<00:57,  1.20it/s]\u001b[A\n","Training loss: 4.20e-01 lr: 9.20e-06:  82% 307/375 [04:16<00:56,  1.20it/s]\u001b[A\n","Training loss: 4.01e-01 lr: 9.07e-06:  82% 308/375 [04:17<00:55,  1.20it/s]\u001b[A\n","Training loss: 3.70e-01 lr: 8.93e-06:  82% 309/375 [04:18<00:54,  1.20it/s]\u001b[A\n","Training loss: 3.78e-01 lr: 8.80e-06:  83% 310/375 [04:18<00:53,  1.21it/s]\u001b[A\n","Training loss: 4.00e-01 lr: 8.67e-06:  83% 311/375 [04:19<00:53,  1.21it/s]\u001b[A\n","Training loss: 4.33e-01 lr: 8.53e-06:  83% 312/375 [04:20<00:52,  1.21it/s]\u001b[A\n","Training loss: 4.12e-01 lr: 8.40e-06:  83% 313/375 [04:21<00:51,  1.21it/s]\u001b[A\n","Training loss: 3.89e-01 lr: 8.27e-06:  84% 314/375 [04:22<00:50,  1.21it/s]\u001b[A\n","Training loss: 3.97e-01 lr: 8.13e-06:  84% 315/375 [04:23<00:49,  1.21it/s]\u001b[A\n","Training loss: 4.00e-01 lr: 8.00e-06:  84% 316/375 [04:23<00:48,  1.21it/s]\u001b[A\n","Training loss: 3.79e-01 lr: 7.87e-06:  85% 317/375 [04:24<00:48,  1.19it/s]\u001b[A\n","Training loss: 3.98e-01 lr: 7.73e-06:  85% 318/375 [04:25<00:47,  1.19it/s]\u001b[A\n","Training loss: 4.20e-01 lr: 7.60e-06:  85% 319/375 [04:26<00:47,  1.19it/s]\u001b[A\n","Training loss: 4.33e-01 lr: 7.47e-06:  85% 320/375 [04:27<00:46,  1.19it/s]\u001b[A\n","Training loss: 3.73e-01 lr: 7.33e-06:  86% 321/375 [04:28<00:45,  1.18it/s]\u001b[A\n","Training loss: 3.94e-01 lr: 7.20e-06:  86% 322/375 [04:29<00:44,  1.19it/s]\u001b[A\n","Training loss: 4.19e-01 lr: 7.07e-06:  86% 323/375 [04:29<00:43,  1.19it/s]\u001b[A\n","Training loss: 4.18e-01 lr: 6.93e-06:  86% 324/375 [04:30<00:42,  1.20it/s]\u001b[A\n","Training loss: 3.86e-01 lr: 6.80e-06:  87% 325/375 [04:31<00:41,  1.20it/s]\u001b[A\n","Training loss: 3.87e-01 lr: 6.67e-06:  87% 326/375 [04:32<00:40,  1.20it/s]\u001b[A\n","Training loss: 3.84e-01 lr: 6.53e-06:  87% 327/375 [04:33<00:39,  1.20it/s]\u001b[A\n","Training loss: 3.93e-01 lr: 6.40e-06:  87% 328/375 [04:33<00:39,  1.20it/s]\u001b[A\n","Training loss: 4.01e-01 lr: 6.27e-06:  88% 329/375 [04:34<00:38,  1.20it/s]\u001b[A\n","Training loss: 3.99e-01 lr: 6.13e-06:  88% 330/375 [04:35<00:37,  1.20it/s]\u001b[A\n","Training loss: 3.42e-01 lr: 6.00e-06:  88% 331/375 [04:36<00:36,  1.21it/s]\u001b[A\n","Training loss: 3.39e-01 lr: 5.87e-06:  89% 332/375 [04:37<00:35,  1.20it/s]\u001b[A\n","Training loss: 3.33e-01 lr: 5.73e-06:  89% 333/375 [04:38<00:34,  1.21it/s]\u001b[A\n","Training loss: 3.48e-01 lr: 5.60e-06:  89% 334/375 [04:38<00:34,  1.20it/s]\u001b[A\n","Training loss: 3.38e-01 lr: 5.47e-06:  89% 335/375 [04:39<00:33,  1.19it/s]\u001b[A\n","Training loss: 3.84e-01 lr: 5.33e-06:  90% 336/375 [04:40<00:32,  1.19it/s]\u001b[A\n","Training loss: 3.56e-01 lr: 5.20e-06:  90% 337/375 [04:41<00:32,  1.18it/s]\u001b[A\n","Training loss: 3.80e-01 lr: 5.07e-06:  90% 338/375 [04:42<00:31,  1.19it/s]\u001b[A\n","Training loss: 4.51e-01 lr: 4.93e-06:  90% 339/375 [04:43<00:30,  1.20it/s]\u001b[A\n","Training loss: 4.33e-01 lr: 4.80e-06:  91% 340/375 [04:44<00:29,  1.20it/s]\u001b[A\n","Training loss: 4.08e-01 lr: 4.67e-06:  91% 341/375 [04:44<00:28,  1.20it/s]\u001b[A\n","Training loss: 3.72e-01 lr: 4.53e-06:  91% 342/375 [04:45<00:27,  1.20it/s]\u001b[A\n","Training loss: 3.71e-01 lr: 4.40e-06:  91% 343/375 [04:46<00:26,  1.20it/s]\u001b[A\n","Training loss: 3.96e-01 lr: 4.27e-06:  92% 344/375 [04:47<00:25,  1.20it/s]\u001b[A\n","Training loss: 3.60e-01 lr: 4.13e-06:  92% 345/375 [04:48<00:24,  1.21it/s]\u001b[A\n","Training loss: 3.60e-01 lr: 4.00e-06:  92% 346/375 [04:48<00:24,  1.21it/s]\u001b[A\n","Training loss: 3.69e-01 lr: 3.87e-06:  93% 347/375 [04:49<00:23,  1.21it/s]\u001b[A\n","Training loss: 4.41e-01 lr: 3.73e-06:  93% 348/375 [04:50<00:22,  1.20it/s]\u001b[A\n","Training loss: 4.50e-01 lr: 3.60e-06:  93% 349/375 [04:51<00:21,  1.21it/s]\u001b[A\n","Training loss: 3.79e-01 lr: 3.47e-06:  93% 350/375 [04:52<00:20,  1.20it/s]\u001b[A\n","Training loss: 3.62e-01 lr: 3.33e-06:  94% 351/375 [04:53<00:20,  1.19it/s]\u001b[A\n","Training loss: 4.02e-01 lr: 3.20e-06:  94% 352/375 [04:54<00:19,  1.19it/s]\u001b[A\n","Training loss: 4.19e-01 lr: 3.07e-06:  94% 353/375 [04:54<00:18,  1.18it/s]\u001b[A\n","Training loss: 4.40e-01 lr: 2.93e-06:  94% 354/375 [04:55<00:17,  1.19it/s]\u001b[A\n","Training loss: 3.88e-01 lr: 2.80e-06:  95% 355/375 [04:56<00:16,  1.19it/s]\u001b[A\n","Training loss: 4.78e-01 lr: 2.67e-06:  95% 356/375 [04:57<00:15,  1.19it/s]\u001b[A\n","Training loss: 4.36e-01 lr: 2.53e-06:  95% 357/375 [04:58<00:15,  1.20it/s]\u001b[A\n","Training loss: 4.04e-01 lr: 2.40e-06:  95% 358/375 [04:59<00:14,  1.20it/s]\u001b[A\n","Training loss: 5.09e-01 lr: 2.27e-06:  96% 359/375 [04:59<00:13,  1.20it/s]\u001b[A\n","Training loss: 4.49e-01 lr: 2.13e-06:  96% 360/375 [05:00<00:12,  1.20it/s]\u001b[A\n","Training loss: 4.36e-01 lr: 2.00e-06:  96% 361/375 [05:01<00:11,  1.20it/s]\u001b[A\n","Training loss: 4.18e-01 lr: 1.87e-06:  97% 362/375 [05:02<00:10,  1.20it/s]\u001b[A\n","Training loss: 4.33e-01 lr: 1.73e-06:  97% 363/375 [05:03<00:09,  1.20it/s]\u001b[A\n","Training loss: 4.03e-01 lr: 1.60e-06:  97% 364/375 [05:04<00:09,  1.20it/s]\u001b[A\n","Training loss: 3.93e-01 lr: 1.47e-06:  97% 365/375 [05:04<00:08,  1.20it/s]\u001b[A\n","Training loss: 4.28e-01 lr: 1.33e-06:  98% 366/375 [05:05<00:07,  1.19it/s]\u001b[A\n","Training loss: 4.67e-01 lr: 1.20e-06:  98% 367/375 [05:06<00:06,  1.19it/s]\u001b[A\n","Training loss: 4.25e-01 lr: 1.07e-06:  98% 368/375 [05:07<00:05,  1.19it/s]\u001b[A\n","Training loss: 4.65e-01 lr: 9.33e-07:  98% 369/375 [05:08<00:05,  1.19it/s]\u001b[A\n","Training loss: 4.64e-01 lr: 8.00e-07:  99% 370/375 [05:09<00:04,  1.19it/s]\u001b[A\n","Training loss: 5.08e-01 lr: 6.67e-07:  99% 371/375 [05:09<00:03,  1.19it/s]\u001b[A\n","Training loss: 4.48e-01 lr: 5.33e-07:  99% 372/375 [05:10<00:02,  1.20it/s]\u001b[A\n","Training loss: 4.30e-01 lr: 4.00e-07:  99% 373/375 [05:11<00:01,  1.20it/s]\u001b[A\n","Training loss: 3.74e-01 lr: 2.67e-07: 100% 374/375 [05:12<00:00,  1.20it/s]\u001b[A\n","Training loss: 3.76e-01 lr: 1.33e-07: 100% 375/375 [05:13<00:00,  1.20it/s]\n","Epoch: 100% 1/1 [05:13<00:00, 313.23s/it]\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}